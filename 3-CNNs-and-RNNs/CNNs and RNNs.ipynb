{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLCL Assignment - 3\n",
    "## Submitted by Chetan Patil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Both the tasks have been trained over Polarity dataset http://www.cs.cornell.edu/people/pabo/movie-review-data/\n",
    "## Task 1:\n",
    "### Part a: Text Classification using CNNs on polarity Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os, glob\n",
    "\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dense, Dropout, Activation, Conv1D, GlobalMaxPooling1D\n",
    "from keras.regularizers import l2\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = []\n",
    "labels = []\n",
    "def read_train_dataset(child, sentence_list, labels_list, label, path = \"./txt_sentoken/\"):\n",
    "    for root, dirs, files in os.walk(path+child):\n",
    "        for file in files:\n",
    "            if file.endswith(\".txt\"):\n",
    "                f = open(path+child+\"/\"+file, \"r\")\n",
    "                for line in f.readlines():\n",
    "                    sentence_list.append(line)\n",
    "                    labels_list.append(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_train_dataset(\"pos\", sentence, labels, \"pos\")\n",
    "read_train_dataset(\"neg\", sentence, labels, \"neg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64720\n"
     ]
    }
   ],
   "source": [
    "print(len(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dictionary = 10000\n",
    "max_seq_len = 20\n",
    "embedding_size = 50\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "filter_size = 3\n",
    "filters = 250\n",
    "hidden_dims = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64720, 20)\n",
      "(64720, 2)\n"
     ]
    }
   ],
   "source": [
    "#preprocessing\n",
    "token = Tokenizer(num_words=vocab_dictionary)\n",
    "token.fit_on_texts(sentence)\n",
    "x = token.texts_to_sequences(sentence)\n",
    "x = sequence.pad_sequences(x, maxlen=max_seq_len)\n",
    "y = labels\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y)\n",
    "y = label_encoder.transform(y)\n",
    "\n",
    "y = to_categorical(y)\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(input_dim=vocab_dictionary, output_dim=embedding_size, input_length=max_seq_len))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(filters=filters, kernel_size=filter_size, strides=1, padding='valid', activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(units=hidden_dims, activation='relu', kernel_regularizer=l2(0.2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_32 (Embedding)     (None, 20, 50)            500000    \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 20, 50)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 18, 250)           37750     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_23 (Glo (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 256)               64256     \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 602,520\n",
      "Trainable params: 602,520\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 51776 samples, validate on 12944 samples\n",
      "Epoch 1/10\n",
      "51776/51776 [==============================] - 27s 516us/step - loss: 0.4214 - acc: 0.8115 - val_loss: 1.3160 - val_acc: 0.4597\n",
      "Epoch 2/10\n",
      "51776/51776 [==============================] - 25s 489us/step - loss: 0.3912 - acc: 0.8263 - val_loss: 1.4108 - val_acc: 0.4302\n",
      "Epoch 3/10\n",
      "51776/51776 [==============================] - 26s 493us/step - loss: 0.3636 - acc: 0.8436 - val_loss: 1.7200 - val_acc: 0.4015\n",
      "Epoch 4/10\n",
      "51776/51776 [==============================] - 29s 561us/step - loss: 0.3360 - acc: 0.8547 - val_loss: 1.3481 - val_acc: 0.4713\n",
      "Epoch 5/10\n",
      "51776/51776 [==============================] - 24s 470us/step - loss: 0.3121 - acc: 0.8691 - val_loss: 1.4748 - val_acc: 0.5157\n",
      "Epoch 6/10\n",
      "51776/51776 [==============================] - 30s 586us/step - loss: 0.2835 - acc: 0.8827 - val_loss: 1.9116 - val_acc: 0.4316\n",
      "Epoch 7/10\n",
      "51776/51776 [==============================] - 28s 532us/step - loss: 0.2670 - acc: 0.8897 - val_loss: 1.7604 - val_acc: 0.5098\n",
      "Epoch 8/10\n",
      "51776/51776 [==============================] - 26s 501us/step - loss: 0.2461 - acc: 0.8996 - val_loss: 1.8580 - val_acc: 0.5382\n",
      "Epoch 9/10\n",
      "51776/51776 [==============================] - 27s 515us/step - loss: 0.2302 - acc: 0.9080 - val_loss: 2.3216 - val_acc: 0.4628\n",
      "Epoch 10/10\n",
      "51776/51776 [==============================] - 27s 523us/step - loss: 0.2165 - acc: 0.9120 - val_loss: 2.6417 - val_acc: 0.4585\n"
     ]
    }
   ],
   "source": [
    "#model fitting\n",
    "history = model.fit(x, y, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neg' 'pos' 'pos' 'neg' 'neg']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "input_vec = [\"I am good\", \"Very bad\", \"That is so awesome\", \"it stinks\", \"enjoying but distressed\"]\n",
    "input_vec = token.texts_to_sequences(input_vec)\n",
    "input_vec = sequence.pad_sequences(input_vec, maxlen=max_seq_len)\n",
    "label_prob = model.predict(input_vec)\n",
    "label_pred = label_prob.argmax(axis=-1)\n",
    "print(label_encoder.inverse_transform(label_pred));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part c: Extending the approaches \n",
    "\n",
    "We can consider ther named entities as well as POS tags for words along with text in order to enrich the features. In case of sentiment analysis we can also consider the tf-idf values in the feature vector. We can also take care of punctuations and include them in text as well as feature vector neglecting the irrelevant punctuations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "### Part a:  Text Classification using RNN's (LSTM) on polarity dataset\n",
    "Same above data is used in this task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64720, 20)\n",
      "(64720, 2)\n"
     ]
    }
   ],
   "source": [
    "#preprocessing\n",
    "token = Tokenizer(num_words=vocab_dictionary)\n",
    "token.fit_on_texts(sentence)\n",
    "x = token.texts_to_sequences(sentence)\n",
    "x = sequence.pad_sequences(x, maxlen=max_seq_len)\n",
    "y = labels\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y)\n",
    "y = label_encoder.transform(y)\n",
    "\n",
    "y = to_categorical(y)\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim = vocab_dictionary, output_dim = embedding_size, input_length = max_seq_len))\n",
    "\n",
    "model.add(LSTM(units = 100, recurrent_dropout=0.3, kernel_regularizer=l2(0.02), recurrent_regularizer=l2(0.02)))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(2))\n",
    "\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_34 (Embedding)     (None, 20, 50)            500000    \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 100)               60400     \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 2)                 202       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 560,602\n",
      "Trainable params: 560,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 51776 samples, validate on 12944 samples\n",
      "Epoch 1/10\n",
      "51776/51776 [==============================] - 32s 624us/step - loss: 0.7956 - acc: 0.6447 - val_loss: 0.9102 - val_acc: 0.3059\n",
      "Epoch 2/10\n",
      "51776/51776 [==============================] - 31s 592us/step - loss: 0.5773 - acc: 0.7102 - val_loss: 0.9832 - val_acc: 0.3276\n",
      "Epoch 3/10\n",
      "51776/51776 [==============================] - 32s 622us/step - loss: 0.5273 - acc: 0.7414 - val_loss: 0.9851 - val_acc: 0.3801\n",
      "Epoch 4/10\n",
      "51776/51776 [==============================] - 32s 618us/step - loss: 0.5038 - acc: 0.7541 - val_loss: 0.9044 - val_acc: 0.4814\n",
      "Epoch 5/10\n",
      "51776/51776 [==============================] - 33s 646us/step - loss: 0.4902 - acc: 0.7605 - val_loss: 1.0984 - val_acc: 0.3395\n",
      "Epoch 6/10\n",
      "51776/51776 [==============================] - 35s 674us/step - loss: 0.4806 - acc: 0.7646 - val_loss: 1.0077 - val_acc: 0.4411\n",
      "Epoch 7/10\n",
      "51776/51776 [==============================] - 35s 677us/step - loss: 0.4725 - acc: 0.7696 - val_loss: 1.2527 - val_acc: 0.3935\n",
      "Epoch 8/10\n",
      "51776/51776 [==============================] - 34s 649us/step - loss: 0.4675 - acc: 0.7697 - val_loss: 1.0287 - val_acc: 0.4994\n",
      "Epoch 9/10\n",
      "51776/51776 [==============================] - 33s 641us/step - loss: 0.4629 - acc: 0.7731 - val_loss: 1.1170 - val_acc: 0.3757\n",
      "Epoch 10/10\n",
      "51776/51776 [==============================] - 34s 649us/step - loss: 0.4569 - acc: 0.7788 - val_loss: 1.1033 - val_acc: 0.4044\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x, y, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pos' 'neg' 'pos' 'neg' 'neg']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "input_vec = [\"I am good\", \"Very bad\", \"That is so awesome\", \"it stinks\", \"enjoying but distressed\"]\n",
    "input_vec = token.texts_to_sequences(input_vec)\n",
    "input_vec = sequence.pad_sequences(input_vec, maxlen=max_seq_len)\n",
    "label_prob = model.predict(input_vec)\n",
    "label_pred = label_prob.argmax(axis=-1)\n",
    "print(label_encoder.inverse_transform(label_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparision of CNN's and RNN's results\n",
    "\n",
    "The same polarity dataset was trained and tested over both CNNs and RNNs where we found the accuracy of RNNs using LSTMs is around 92% which is more than what we obtained using CNNs i.e 88%. We can also see that the first predicted sentence being explicitly stated good is not considered positive while LSTMs performed better over the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/\n",
    "https://cambridgespark.com/content/tutorials/convolutional-neural-networks-with-keras/index.html\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
